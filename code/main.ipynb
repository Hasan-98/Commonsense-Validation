{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.parse import ChartParser\n",
    "from nltk.grammar import CFG\n",
    "import nltk\n",
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "import argparse\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser(description='input file name')\n",
    "# parser.add_argument('--input',required=True, help=\"Please add the input file name path and name\")\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# Read Data from input file given by args.\n",
    "# df=pd.read_csv(args.input, sep='\\t',index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"\\n# Load pre-trained model tokenizer (vocabulary)\\ntokenizer = BertTokenizer.from_pretrained('./tmp/swag_output/')\\n# Load pre-trained model (weights)\\nmodel = BertForMaskedLM.from_pretrained('./tmp/swag_output/')\\nmodel.eval()\\n\""
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "def predict(text, bert_model, bert_tokenizer):\n",
    "    # Tokenized input\n",
    "    # text = \"[CLS] I got restricted because Tom reported my reply [SEP]\"\n",
    "    text = \"[CLS] \" + text + \" [SEP]\"\n",
    "    tokenized_text = bert_tokenizer.tokenize(text)\n",
    "    # text = \"[CLS] Stir the mixture until it is done [SEP]\"\n",
    "        #masked_index = 4\n",
    "    sentence_prob = 1\n",
    "    for masked_index in range(1,len(tokenized_text)-1):\n",
    "        # Mask a token that we will try to predict back with `BertForMaskedLM`\n",
    "        masked_word = tokenized_text[masked_index]\n",
    "        #tokenized_text[masked_index] = '[MASK]'\n",
    "        # assert tokenized_text == ['[CLS]', 'who', 'was', 'jim', 'henson', '?', '[SEP]', 'jim', '[MASK]', 'was', 'a', 'puppet', '##eer', '[SEP]']\n",
    "        # print (tokenized_text)\n",
    "\n",
    "        # Convert token to vocabulary indices\n",
    "        indexed_tokens = bert_tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "        # Define sentence A and B indices associated to 1st and 2nd sentences (see paper)\n",
    "        # segments_ids = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]\n",
    "        length = len(tokenized_text)\n",
    "        segments_ids = [0 for _ in range(length)]\n",
    "        # Convert inputs to PyTorch tensors\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "        # If you have a GPU, put everything on cuda\n",
    "        # tokens_tensor = tokens_tensor.to('cuda')\n",
    "        # segments_tensors = segments_tensors.to('cuda')\n",
    "\n",
    "        # Load pre-trained model (weights)\n",
    "        # bert_model = BertForMaskedLM.from_pretrained('bert-large-uncased')\n",
    "        # bert_model.eval()\n",
    "\n",
    "        # If you have a GPU, put everything on cuda\n",
    "        # tokens_tensor = tokens_tensor.to('cuda')\n",
    "        # segments_tensors = segments_tensors.to('cuda')\n",
    "        # bert_model.to('cuda')\n",
    "\n",
    "        # Predict all tokens\n",
    "        with torch.no_grad():\n",
    "            predictions = bert_model(tokens_tensor, segments_tensors)\n",
    "\n",
    "        predictions = torch.nn.functional.softmax(predictions, -1)\n",
    "\n",
    "        index = bert_tokenizer.convert_tokens_to_ids([masked_word])[0]\n",
    "\n",
    "        curr_prob = predictions[0, masked_index][index]\n",
    "        # predict_list = predictions[0, masked_index]\n",
    "        sentence_prob *= curr_prob\n",
    "        #tokenized_text[masked_index] = masked_word\n",
    "    return math.pow(sentence_prob, 1/(len(tokenized_text)-3))\n",
    "    #return sentence_prob\n",
    "'''\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('./tmp/swag_output/')\n",
    "# Load pre-trained model (weights)\n",
    "model = BertForMaskedLM.from_pretrained('./tmp/swag_output/')\n",
    "model.eval()\n",
    "'''\n"
   ]
  },
  {
   "source": [
    "# Task A"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../ALL data/Training  Data/subtaskA_data_all.csv', sep=',',index_col='id')\n",
    "df_label=pd.read_csv('../ALL data/Training  Data/subtaskA_answers_all.csv', sep=',',header=None,index_col=0)\n",
    "df_label.columns=['label-false']\n",
    "df=df.join(df_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                  sent0  \\\n",
       "id                                                        \n",
       "0                 He poured orange juice on his cereal.   \n",
       "1                                      He drinks apple.   \n",
       "2                                 Jeff ran a mile today   \n",
       "3                                  A mosquito stings me   \n",
       "4                                  A niece is a person.   \n",
       "...                                                 ...   \n",
       "9995                   Mark ate a big bitter cherry pie   \n",
       "9996                     Gloria wears a cat on her head   \n",
       "9997  Harry went to the barbershop to have his hair cut   \n",
       "9998                    Reilly is sleeping on the couch   \n",
       "9999                           I have a desk on my lamp   \n",
       "\n",
       "                                                  sent1  label-false  \n",
       "id                                                                    \n",
       "0                         He poured milk on his cereal.            0  \n",
       "1                                       He drinks milk.            0  \n",
       "2                          Jeff ran 100,000 miles today            1  \n",
       "3                                    I sting a mosquito            1  \n",
       "4                                A giraffe is a person.            1  \n",
       "...                                                 ...          ...  \n",
       "9995                    Mark ate a big sweet cherry pie            0  \n",
       "9996                     Gloria wears a hat on her head            0  \n",
       "9997  Harry went to the barbershop to have his glass...            1  \n",
       "9998                   Reilly is sleeping on the window            1  \n",
       "9999                           I have a lamp on my desk            0  \n",
       "\n",
       "[10000 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sent0</th>\n      <th>sent1</th>\n      <th>label-false</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>He poured orange juice on his cereal.</td>\n      <td>He poured milk on his cereal.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>He drinks apple.</td>\n      <td>He drinks milk.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Jeff ran a mile today</td>\n      <td>Jeff ran 100,000 miles today</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A mosquito stings me</td>\n      <td>I sting a mosquito</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A niece is a person.</td>\n      <td>A giraffe is a person.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>Mark ate a big bitter cherry pie</td>\n      <td>Mark ate a big sweet cherry pie</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>Gloria wears a cat on her head</td>\n      <td>Gloria wears a hat on her head</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>Harry went to the barbershop to have his hair cut</td>\n      <td>Harry went to the barbershop to have his glass...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>Reilly is sleeping on the couch</td>\n      <td>Reilly is sleeping on the window</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>I have a desk on my lamp</td>\n      <td>I have a lamp on my desk</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows Ã— 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(10000, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select specific part of datframe\n",
    "df1=df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): BertLayerNorm()\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# Load pre-trained model (weights)\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.39989597379060515\n",
      "-------------\n",
      "0.42548061000793774\n",
      "-------------\n",
      "0.5156204540425442\n",
      "-------------\n",
      "0.4335789488698799\n",
      "-------------\n",
      "0.5957062266924752\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "for index, row in df1.iterrows():  \n",
    "# tokenize the rows of dataframe (pos column)\n",
    "    sentence_1 = row['sent0']\n",
    "    sentence_2 = row['sent1']\n",
    "\n",
    "    prob_1 = predict(sentence_1, bert_model=model, bert_tokenizer=tokenizer)\n",
    "    prob_2 = predict(sentence_2, bert_model=model, bert_tokenizer=tokenizer) \n",
    "    df1.loc[index,'prob_1']=prob_1\n",
    "    df1.loc[index,'prob_2']=prob_2\n",
    "    df1.loc[index,'predicted_false']=np.argmin([prob_1, prob_2]).astype('int64')\n",
    "\n",
    "    print(np.min([prob_1, prob_2]))\n",
    "    print('-------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                    sent0                          sent1  \\\n",
       "id                                                                         \n",
       "0   He poured orange juice on his cereal.  He poured milk on his cereal.   \n",
       "1                        He drinks apple.                He drinks milk.   \n",
       "2                   Jeff ran a mile today   Jeff ran 100,000 miles today   \n",
       "3                    A mosquito stings me             I sting a mosquito   \n",
       "4                    A niece is a person.         A giraffe is a person.   \n",
       "\n",
       "    label-false    prob_1    prob_2  predicted_false  \n",
       "id                                                    \n",
       "0             0  0.399896  0.768483              0.0  \n",
       "1             0  0.610041  0.425481              1.0  \n",
       "2             1  0.603129  0.515620              1.0  \n",
       "3             1  0.458191  0.433579              1.0  \n",
       "4             1  0.715048  0.595706              1.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sent0</th>\n      <th>sent1</th>\n      <th>label-false</th>\n      <th>prob_1</th>\n      <th>prob_2</th>\n      <th>predicted_false</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>He poured orange juice on his cereal.</td>\n      <td>He poured milk on his cereal.</td>\n      <td>0</td>\n      <td>0.399896</td>\n      <td>0.768483</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>He drinks apple.</td>\n      <td>He drinks milk.</td>\n      <td>0</td>\n      <td>0.610041</td>\n      <td>0.425481</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Jeff ran a mile today</td>\n      <td>Jeff ran 100,000 miles today</td>\n      <td>1</td>\n      <td>0.603129</td>\n      <td>0.515620</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A mosquito stings me</td>\n      <td>I sting a mosquito</td>\n      <td>1</td>\n      <td>0.458191</td>\n      <td>0.433579</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A niece is a person.</td>\n      <td>A giraffe is a person.</td>\n      <td>1</td>\n      <td>0.715048</td>\n      <td>0.595706</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy is equal to: 80.0 %\n"
     ]
    }
   ],
   "source": [
    "# print accuracy report\n",
    "print(f\"Accuracy is equal to: {((df1['label-false']==df1['predicted_false']).sum()/df1.shape[0])*100} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import GPT2Tokenizer, GPT2Model\n",
    "# tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "# model = GPT2Model.from_pretrained('gpt2')\n",
    "# text = \"Replace me by any text you'd like.\"\n",
    "# encoded_input = tokenizer(text, return_tensors='pt')\n",
    "# output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "# model.eval()\n",
    "# tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# def score(sentence):\n",
    "#     tokenize_input = tokenizer.tokenize(sentence)\n",
    "#     tensor_input = torch.tensor([tokenizer.convert_tokens_to_ids(tokenize_input)])\n",
    "#     loss=model(tensor_input, labels=tensor_input)\n",
    "#     return -loss[0] * len(tokenize_input)\n",
    "\n",
    "# a=['there is a book on the desk',\n",
    "#                 'there is a plane on the desk',\n",
    "#                         'there is a book in the desk']\n",
    "# print([score(i) for i in a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
    "# model_id = 'gpt2'\n",
    "# # model_id = 'gpt2-large'\n",
    "# model = GPT2LMHeadModel.from_pretrained(model_id)\n",
    "# tokenizer = GPT2TokenizerFast.from_pretrained(model_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('nlp_env': conda)",
   "display_name": "Python 3.8.5 64-bit ('nlp_env': conda)",
   "metadata": {
    "interpreter": {
     "hash": "d3b11afc1419d2e372e9e23e645a6813b53ad6225361ec94a05870210063ecc9"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}